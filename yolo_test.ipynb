{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb5785c3",
   "metadata": {},
   "source": [
    "## Yolo Detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fff91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W rknn-toolkit-lite2 version: 2.3.2\n",
      "W Query dynamic range failed. Ret code: RKNN_ERR_MODEL_INVALID. (If it is a static shape RKNN model, please ignore the above warning message.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO : --> Load YOLO model\n",
      "done\n",
      "YOLO : --> Init runtime environment YOLO\n",
      "I RKNN: [19:52:21.752] RKNN Runtime Information, librknnrt version: 2.3.2 (429f97ae6b@2025-04-09T09:09:27)\n",
      "I RKNN: [19:52:21.752] RKNN Driver Information, version: 0.9.8\n",
      "I RKNN: [19:52:21.752] RKNN Model Information, version: 6, toolkit version: 2.3.2(compiler version: 2.3.2 (e045de294f@2025-04-07T19:48:25)), target: RKNPU v2, target platform: rk3588, framework name: ONNX, framework layout: NCHW, model inference type: static_shape\n",
      "W RKNN: [19:52:21.760] query RKNN_QUERY_INPUT_DYNAMIC_RANGE error, rknn model is static shape type, please export rknn with dynamic_shapes\n",
      "done\n",
      "YOLO : Inference time: 13.057231903076172 ms\n",
      "13.057231903076172\n",
      "YOLO : RKNN Detect Release!!\n"
     ]
    }
   ],
   "source": [
    "from yolo import *\n",
    "import cv2\n",
    "\n",
    "# Detect and Seg\n",
    "DS_NMS_THRESH = 0.45\n",
    "DS_OBJ_THRESH = 0.25\n",
    "\n",
    "#Seg\n",
    "MAX_DETECT = 300\n",
    "\n",
    "#Pose and OBB\n",
    "PO_NMS_THRESH = 0.4\n",
    "PO_OBJ_THRESH = 0.5\n",
    "\n",
    "\n",
    "#Common\n",
    "DATASET = COCO\n",
    "\n",
    "KEY_ESCAPE = 27\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if DATASET == COCO :\n",
    "        RK3588_RKNN_MODEL = './models/detect/yolo11n-RK3588_320_i8.rknn'\n",
    "        IMG_SIZE = 320\n",
    "        IMG_PATH = './images/detect.jpg'\n",
    "    elif DATASET == FIRE :\n",
    "        #RK3588_RKNN_MODEL = 'detect/yolov11/yolo11s-fire-RK3588_640_i8.rknn'\n",
    "        #IMG_SIZE = 640\n",
    "        RK3588_RKNN_MODEL = './models/detect/yolo11s-fire-RK3588_320_i8.rknn'\n",
    "        IMG_SIZE = 320\n",
    "        IMG_PATH = './images/smoke.jpg'\n",
    "    elif DATASET == LICENSE :\n",
    "        RK3588_RKNN_MODEL = './models/detect/LicensePlate-RK3588_320_i8.rknn'\n",
    "        IMG_SIZE = 320\n",
    "        IMG_PATH = './images/LicensePlate.jpg'\n",
    "    '''\n",
    "    # Yolo(\n",
    "    # TASK, \n",
    "    # RK3588_RKNN_MODEL, \n",
    "    # input_size = 640, \n",
    "    # DATASET = COCO, \n",
    "    # DS_NMS_THRESH = 0.45, \n",
    "    # DS_OBJ_THRESH = 0.25, \n",
    "    # PO_NMS_THRESH = 0.4, \n",
    "    # PO_OBJ_THRESH = 0.5, \n",
    "    # MAX_DETECT = 300\n",
    "    #)\n",
    "    '''\n",
    "    yolo = Yolo( \"detect\", RK3588_RKNN_MODEL, input_size = IMG_SIZE, DATASET=DATASET)\n",
    "    img_org = cv2.imread(IMG_PATH)\n",
    "    boxes, classes, scores = yolo.detect(img_org)\n",
    "    if boxes is not None:\n",
    "        yolo.detect.draw(img_org, boxes, scores, classes, \"all\", label=True)\n",
    "\n",
    "    cv2.imshow(\"post process result\", img_org)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    #show_rgb_image(img_org, 'post process result')\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    yolo.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e686c873",
   "metadata": {},
   "source": [
    "## Yolo Pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de628cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W rknn-toolkit-lite2 version: 2.3.2\n",
      "W Query dynamic range failed. Ret code: RKNN_ERR_MODEL_INVALID. (If it is a static shape RKNN model, please ignore the above warning message.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO : --> Load YOLO model\n",
      "done\n",
      "YOLO : --> Init runtime environment YOLO\n",
      "I RKNN: [00:28:10.111] RKNN Runtime Information, librknnrt version: 2.3.2 (429f97ae6b@2025-04-09T09:09:27)\n",
      "I RKNN: [00:28:10.111] RKNN Driver Information, version: 0.9.8\n",
      "I RKNN: [00:28:10.112] RKNN Model Information, version: 6, toolkit version: 2.3.2(compiler version: 2.3.2 (e045de294f@2025-04-07T19:48:25)), target: RKNPU v2, target platform: rk3588, framework name: ONNX, framework layout: NCHW, model inference type: static_shape\n",
      "W RKNN: [00:28:10.120] query RKNN_QUERY_INPUT_DYNAMIC_RANGE error, rknn model is static shape type, please export rknn with dynamic_shapes\n",
      "done\n",
      "YOLO : Inference time: 12.218713760375977 ms\n",
      "YOLO : RKNN Pose Release!!\n"
     ]
    }
   ],
   "source": [
    "from yolo import *\n",
    "import cv2\n",
    "\n",
    "# Detect and Seg\n",
    "DS_NMS_THRESH = 0.45\n",
    "DS_OBJ_THRESH = 0.25\n",
    "\n",
    "#Seg\n",
    "MAX_DETECT = 300\n",
    "\n",
    "#Pose and OBB\n",
    "PO_NMS_THRESH = 0.4\n",
    "PO_OBJ_THRESH = 0.5\n",
    "\n",
    "\n",
    "#Common\n",
    "DATASET = COCO\n",
    "IMG_SIZE = 320\n",
    "\n",
    "KEY_ESCAPE = 27\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    RK3588_RKNN_MODEL = \"./models/pose/yolo11n-pose-RK3588_320x320_i8.rknn\"\n",
    "    IMG_PATH = './images/pose.jpg'\n",
    "    '''\n",
    "    # Yolo(\n",
    "    # TASK, \n",
    "    # RK3588_RKNN_MODEL, \n",
    "    # input_size = 640, \n",
    "    # DATASET = COCO, \n",
    "    # DS_NMS_THRESH = 0.45, \n",
    "    # DS_OBJ_THRESH = 0.25, \n",
    "    # PO_NMS_THRESH = 0.4, \n",
    "    # PO_OBJ_THRESH = 0.5, \n",
    "    # MAX_DETECT = 300\n",
    "    #)\n",
    "    '''\n",
    "    yolo = Yolo( \"pose\", RK3588_RKNN_MODEL, input_size = IMG_SIZE, DATASET=DATASET, CALC_ANGLE=True)\n",
    "    img_org = cv2.imread(IMG_PATH)\n",
    "    predbox = yolo.pose(img_org)\n",
    "    yolo.pose.draw(img_org, predbox, box_vis = False, angle=False)\n",
    "    cv2.imshow(\"post process result\", img_org)\n",
    "    cv2.waitKey(0)\n",
    "    # Release\n",
    "    cv2.destroyAllWindows()\n",
    "    yolo.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf1f267",
   "metadata": {},
   "source": [
    "## Yolo Seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e357103",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darkice/miniconda3/envs/pyside6rknn/lib/python3.12/site-packages/rknnlite/api/rknn_lite.py:41: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "W rknn-toolkit-lite2 version: 2.3.2\n",
      "W Query dynamic range failed. Ret code: RKNN_ERR_MODEL_INVALID. (If it is a static shape RKNN model, please ignore the above warning message.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO : --> Load YOLO model\n",
      "done\n",
      "YOLO : --> Init runtime environment YOLO\n",
      "I RKNN: [11:50:17.940] RKNN Runtime Information, librknnrt version: 2.3.2 (429f97ae6b@2025-04-09T09:09:27)\n",
      "I RKNN: [11:50:17.940] RKNN Driver Information, version: 0.9.8\n",
      "I RKNN: [11:50:17.940] RKNN Model Information, version: 6, toolkit version: 2.3.2(compiler version: 2.3.2 (e045de294f@2025-04-07T19:48:25)), target: RKNPU v2, target platform: rk3588, framework name: ONNX, framework layout: NCHW, model inference type: static_shape\n",
      "W RKNN: [11:50:17.952] query RKNN_QUERY_INPUT_DYNAMIC_RANGE error, rknn model is static shape type, please export rknn with dynamic_shapes\n",
      "done\n",
      "639 480\n",
      "YOLO : inference time : 37.4903678894043ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring XDG_SESSION_TYPE=wayland on Gnome. Use QT_QPA_PLATFORM=wayland to run on Wayland anyway.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO : RKNN Seg Release!!\n"
     ]
    }
   ],
   "source": [
    "from yolo import *\n",
    "import cv2\n",
    "\n",
    "# Detect and Seg\n",
    "DS_NMS_THRESH = 0.45\n",
    "DS_OBJ_THRESH = 0.25\n",
    "\n",
    "#Seg\n",
    "MAX_DETECT = 300\n",
    "\n",
    "#Pose and OBB\n",
    "PO_NMS_THRESH = 0.4\n",
    "PO_OBJ_THRESH = 0.5\n",
    "\n",
    "\n",
    "#Common\n",
    "DATASET = GARBAGE\n",
    "IMG_SIZE = 640\n",
    "\n",
    "KEY_ESCAPE = 27\n",
    "\n",
    "def myletterbox(image, target_width, target_height, bg_color):\n",
    "    \"\"\"\n",
    "    letterbox the image according to the specified size\n",
    "    :param image: input image, which can be a NumPy array or file path\n",
    "    :param size: target size (width, height)\n",
    "    :param bg_color: background filling data \n",
    "    :return: processed image\n",
    "    \"\"\"\n",
    "    if isinstance(image, str):\n",
    "        image = cv2.imread(image)\n",
    "\n",
    "    #target_width, target_height = input_size, input_size\n",
    "    image_height, image_width, _ = image.shape\n",
    "\n",
    "    # Calculate the adjusted image size\n",
    "    aspect_ratio = min(target_width / image_width, target_height / image_height)\n",
    "    new_width = int(image_width * aspect_ratio)\n",
    "    new_height = int(image_height * aspect_ratio)\n",
    "    print( new_width, new_height)\n",
    "    # Use cv2.resize() for proportional scaling\n",
    "    image_resize = cv2.resize(image, (target_width, target_height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # Create a new canvas and fill it\n",
    "    result_image = np.ones((target_height, target_width, 3), dtype=np.uint8) * bg_color\n",
    "    #offset_x = (target_width - new_width) // 2\n",
    "    #offset_y = (target_height - new_height) // 2\n",
    "    result_image[0:target_height, 0:target_width] = image_resize\n",
    "    return result_image, aspect_ratio\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if DATASET == CRACK:\n",
    "        RK3588_RKNN_MODEL = './models/seg/yolov11_crack/yolo11n-crack-RK3588_640_i8.rknn'\n",
    "        IMG_PATH = './images/crack.jpg'\n",
    "    if DATASET == GARBAGE:\n",
    "        RK3588_RKNN_MODEL = './models/seg/yolov11_garbage/yolov11n_taco-RK3588_640_i8.rknn'\n",
    "        IMG_PATH = './images/garbage.jpg'\n",
    "    '''\n",
    "    # Yolo(\n",
    "    # TASK, \n",
    "    # RK3588_RKNN_MODEL, \n",
    "    # input_size = 640, \n",
    "    # DATASET = COCO, \n",
    "    # DS_NMS_THRESH = 0.45, \n",
    "    # DS_OBJ_THRESH = 0.25, \n",
    "    # PO_NMS_THRESH = 0.4, \n",
    "    # PO_OBJ_THRESH = 0.5, \n",
    "    # MAX_DETECT = 300\n",
    "    #)\n",
    "    '''\n",
    "    yolo = Yolo( \"seg\", RK3588_RKNN_MODEL, input_size = IMG_SIZE, DATASET=DATASET)\n",
    "    img_org = cv2.imread(IMG_PATH)\n",
    "    #img_letter = cv2.resize(img_org, (639, 480), interpolation=cv2.INTER_AREA)\n",
    "    #result_image = np.ones((480, 640, 3), dtype=np.uint8) * 114\n",
    "    #result_image[0:480, 0:639] = img_letter\n",
    "    #print( result_image.shape)\n",
    "    img_letter, ratio = myletterbox( img_org , 640, 480, 114 )\n",
    "    boxes, classes, scores, seg_img = yolo.seg(img_letter)\n",
    "    if boxes is not None:\n",
    "        img_p = yolo.seg.merge_seg(img_letter, seg_img, classes)\n",
    "        yolo.seg.draw(img_p, boxes, scores, classes, \"all\", label=True)\n",
    "    else:\n",
    "        print( \"Box is None.\")\n",
    "\n",
    "    cv2.imshow(\"post process result\", img_p)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    #show_rgb_image(img_org, 'post process result')\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    yolo.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ff1a82",
   "metadata": {},
   "source": [
    "## Yolo OBB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a9b8e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W rknn-toolkit-lite2 version: 2.3.2\n",
      "W Query dynamic range failed. Ret code: RKNN_ERR_MODEL_INVALID. (If it is a static shape RKNN model, please ignore the above warning message.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO : --> Load YOLO model\n",
      "done\n",
      "YOLO : --> Init runtime environment YOLO\n",
      "I RKNN: [19:21:01.871] RKNN Runtime Information, librknnrt version: 2.3.2 (429f97ae6b@2025-04-09T09:09:27)\n",
      "I RKNN: [19:21:01.871] RKNN Driver Information, version: 0.9.8\n",
      "I RKNN: [19:21:01.872] RKNN Model Information, version: 6, toolkit version: 2.3.2(compiler version: 2.3.2 (e045de294f@2025-04-07T19:48:25)), target: RKNPU v2, target platform: rk3588, framework name: ONNX, framework layout: NCHW, model inference type: static_shape\n",
      "W RKNN: [19:21:01.883] query RKNN_QUERY_INPUT_DYNAMIC_RANGE error, rknn model is static shape type, please export rknn with dynamic_shapes\n",
      "done\n",
      "YOLO : --> Running model\n",
      "YOLO : Inference time: 36.74030303955078ms\n",
      "predbox time: 8382.450580596924ms\n",
      "draw time: 5.85484504699707ms\n",
      "YOLO : RKNN OBB Release!!\n"
     ]
    }
   ],
   "source": [
    "from yolo import *\n",
    "import cv2\n",
    "\n",
    "# Detect and Seg\n",
    "DS_NMS_THRESH = 0.45\n",
    "DS_OBJ_THRESH = 0.25\n",
    "\n",
    "#Seg\n",
    "MAX_DETECT = 300\n",
    "\n",
    "#Pose and OBB\n",
    "PO_NMS_THRESH = 0.4\n",
    "PO_OBJ_THRESH = 0.5\n",
    "\n",
    "\n",
    "#Common\n",
    "DATASET = COCO\n",
    "IMG_SIZE = 640\n",
    "\n",
    "KEY_ESCAPE = 27\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    IMG_PATH = './images/obb.jpg'\n",
    "    IMG_SIZE = 640\n",
    "    RK3588_RKNN_MODEL = \"./models/obb/yolo11n-obb-RK3588_i8.rknn\"\n",
    "    '''\n",
    "    # Yolo(\n",
    "    # TASK, \n",
    "    # RK3588_RKNN_MODEL, \n",
    "    # input_size = 640, \n",
    "    # DATASET = COCO, \n",
    "    # DS_NMS_THRESH = 0.45, \n",
    "    # DS_OBJ_THRESH = 0.25, \n",
    "    # PO_NMS_THRESH = 0.4, \n",
    "    # PO_OBJ_THRESH = 0.5, \n",
    "    # MAX_DETECT = 300\n",
    "    #)\n",
    "    '''\n",
    "    yolo = Yolo( \"obb\", RK3588_RKNN_MODEL, input_size = IMG_SIZE)\n",
    "\n",
    "    # Set inputs\n",
    "    img = cv2.imread(IMG_PATH)\n",
    "    start_time = time.time()\n",
    "    predbox = yolo.obb(img)\n",
    "    print(f'predbox time: {(time.time() - start_time)*1000}ms')\n",
    "    start_time = time.time()\n",
    "    draw_img = yolo.obb.draw(predbox)\n",
    "    print(f'draw time: {(time.time() - start_time)*1000}ms')\n",
    "\n",
    "    cv2.imshow(\"post process result\", draw_img)\n",
    "    cv2.waitKey(0)\n",
    "    # Release\n",
    "    cv2.destroyAllWindows()\n",
    "    yolo.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyside6rknn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
